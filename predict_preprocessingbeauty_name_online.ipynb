{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import subprocess\n",
    "import os\n",
    "from six.moves import urllib\n",
    "import tempfile\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing import sequence\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from gensim.parsing.preprocessing import remove_stopwords\n",
    "from gensim.parsing.preprocessing import strip_punctuation\n",
    "from gensim.parsing.preprocessing import strip_multiple_whitespaces\n",
    "from gensim.parsing.preprocessing import strip_non_alphanum\n",
    "from unidecode import unidecode\n",
    "import spacy\n",
    "import re\n",
    "import xml\n",
    "spacy.prefer_gpu()\n",
    "# sp = spacy.load('en_core_web_sm', disable=['parser', 'ner'])\n",
    "TAG_RE = re.compile(r'<[^>]+>')\n",
    "import util as ut\n",
    "data_filename = '../beauty.csv'\n",
    "\n",
    "TAG_RE = re.compile(r'<[^>]+>')\n",
    "def remove_tags(text):\n",
    "    return TAG_RE.sub('', text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def strip_custom(token):\n",
    "    token = token.replace('&Reg;', \" \")\n",
    "    token = token.replace(\"&lt;\", \"<\")\n",
    "    token = token.replace(\"&times;\", \"\")\n",
    "    token = token.replace(\"&gt;\", \">\")\n",
    "    token = token.replace(\"&quot;\", \"\")\n",
    "    token = token.replace('&nbsp', \" \")\n",
    "    token = token.replace('&copy;', \" \")\n",
    "    token = token.replace('&reg', \" \")\n",
    "    token = token.replace('%20', \" \")\n",
    "    # this has to be last:\n",
    "    token = token.replace(\"&amp;\", \"&\")\n",
    "    token = token.replace(\"â\\x80¢\", \" \")\n",
    "    token = token.replace(\"Â®\", \" \")\n",
    "    token = token.replace(\"Ã©\", \" \")\n",
    "    token = token.replace(\"®\", \" \")\n",
    "    token = token.replace(\"©\", \" \")\n",
    "    token = token.replace(\"™\", \" \")\n",
    "    token = token.replace(\"•\", \"\")\n",
    "    token = token.replace(\"�\", \"\")\n",
    "    \n",
    "    token = token.replace(\"width:99pt\", \"\")\n",
    "    token = token.replace('class=\"xl66\">', '')\n",
    "    #token = re.sub(r\"\\'\", '', token)\n",
    "    token = token.replace('&#160;', ' ')\n",
    "    return token\n",
    "\n",
    "\n",
    "def string_processor(token):\n",
    "\n",
    "#     str = unidecode(token)\n",
    "    str = token.lower()\n",
    "    str = strip_custom(str)\n",
    "    str = remove_stopwords(str)\n",
    "    str = strip_punctuation(str)\n",
    "    str = remove_tags(str)\n",
    "    str = strip_non_alphanum(str)\n",
    "#     tokens = sp(str)\n",
    "#     tokens = [token.lemma_ for token in tokens]\n",
    "#     str = \" \".join(tokens)\n",
    "    str = strip_multiple_whitespaces(str)\n",
    "\n",
    "    return str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def processing_sequences(x_test,maxlen=16,ngram_range=1):\n",
    "    print(len(x_test), 'test sequences')\n",
    "\n",
    "    print('Average test sequence length: {}'.format(\n",
    "        np.mean(list(map(len, x_test)))))\n",
    "\n",
    "    if ngram_range > 1:\n",
    "        print('Adding {}-gram features'.format(ngram_range))\n",
    "        # Create set of unique n-gram from the training set.\n",
    "        ngram_set = set()\n",
    "        for input_list in x_train:\n",
    "            for i in range(2, ngram_range + 1):\n",
    "                set_of_ngram = create_ngram_set(input_list, ngram_value=i)\n",
    "                ngram_set.update(set_of_ngram)\n",
    "\n",
    "        # Dictionary mapping n-gram token to a unique integer.\n",
    "        # Integer values are greater than max_features in order\n",
    "        # to avoid collision with existing features.\n",
    "        start_index = max_features + 1\n",
    "        token_indice = {v: k + start_index for k, v in enumerate(ngram_set)}\n",
    "        indice_token = {token_indice[k]: k for k in token_indice}\n",
    "\n",
    "        # max_features is the highest integer that could be found in the dataset.\n",
    "        max_features = np.max(list(indice_token.keys())) + 1\n",
    "        print(\"max_features:\",max_features)\n",
    "\n",
    "        # Augmenting x_train and x_test with n-grams features\n",
    "\n",
    "        x_test = add_ngram(x_test, token_indice, ngram_range)\n",
    "\n",
    "        print('Average test sequence length: {}'.format(\n",
    "            np.mean(list(map(len, x_test)), dtype=int)))\n",
    "\n",
    "    print('Pad sequences (samples x time)')\n",
    "\n",
    "    x_test = sequence.pad_sequences(x_test, maxlen=maxlen)\n",
    "\n",
    "    print('x_test shape:', x_test.shape)\n",
    "    return x_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before drop:  87877\n",
      "after drop:  87854\n",
      "87854 test sequences\n",
      "Average test sequence length: 6.957190338516175\n",
      "Pad sequences (samples x time)\n",
      "x_test shape: (87854, 16)\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(data_filename)\n",
    "df = df[['bucket_name','product_name']]\n",
    "print(\"before drop: \",len(df))\n",
    "df = df.dropna()\n",
    "print(\"after drop: \",len(df))\n",
    "# to lowercase\n",
    "df.product_name = df.product_name.apply(lambda x : str(x).lower())\n",
    "df.product_name = df.product_name.apply(lambda x : string_processor(x))\n",
    "\n",
    "corpus = df.product_name.tolist()\n",
    "\n",
    "\n",
    "vocabulary_size = 20000\n",
    "tokenizer = Tokenizer(num_words= vocabulary_size, \n",
    "                      filters='!\"#$%&()*+,-./:;<=>?@[\\\\]^_`{|}~\\t\\n', \n",
    "                      lower=True, \n",
    "                      split=' ')\n",
    "\n",
    "tokenizer.fit_on_texts(corpus)\n",
    "sequences = tokenizer.texts_to_sequences(corpus)\n",
    "sequences = np.array(sequences)\n",
    "\n",
    "\n",
    "X_test = processing_sequences(sequences,maxlen=16,ngram_range=1)\n",
    "# X = np.array(sequences)\n",
    "# y = np.array(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "No module named 'googleapiclient'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-8905dc7a4007>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mgoogleapiclient\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdiscovery\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mpredict_json\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mproject\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minstances\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mversion\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \"\"\"Send json data to a deployed model for prediction.\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: No module named 'googleapiclient'"
     ]
    }
   ],
   "source": [
    "import googleapiclient.discovery\n",
    "\n",
    "def predict_json(project, model, instances, version=None):\n",
    "    \"\"\"Send json data to a deployed model for prediction.\n",
    "\n",
    "    Args:\n",
    "        project (str): project where the Cloud ML Engine Model is deployed.\n",
    "        model (str): model name.\n",
    "        instances ([Mapping[str: Any]]): Keys should be the names of Tensors\n",
    "            your deployed model expects as inputs. Values should be datatypes\n",
    "            convertible to Tensors, or (potentially nested) lists of datatypes\n",
    "            convertible to tensors.\n",
    "        version: str, version of the model to target.\n",
    "    Returns:\n",
    "        Mapping[str: any]: dictionary of prediction results defined by the\n",
    "            model.\n",
    "    \"\"\"\n",
    "    # Create the ML Engine service object.\n",
    "    # To authenticate set the environment variable\n",
    "    # GOOGLE_APPLICATION_CREDENTIALS=<path_to_service_account_file>\n",
    "    service = googleapiclient.discovery.build('ml', 'v1')\n",
    "    name = 'projects/{}/models/{}'.format(project, model)\n",
    "\n",
    "    if version is not None:\n",
    "        name += '/versions/{}'.format(version)\n",
    "\n",
    "    response = service.projects().predict(\n",
    "        name=name,\n",
    "        body={'instances': instances}\n",
    "    ).execute()\n",
    "\n",
    "    if 'error' in response:\n",
    "        raise RuntimeError(response['error'])\n",
    "\n",
    "    return response['predictions']\n",
    "\n",
    "\n",
    "# def get_true_label(encoder,y_hats):\n",
    "#     labels = [np.argmax(np.array(i['dense'])) for i in y_hats]\n",
    "#     return encoder.inverse_transform(labels),labels\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "inc = X_test[33137:33137+30].tolist()\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "encoder = LabelEncoder()\n",
    "encoder.classes_ = np.load('saved_encoder.npy',allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hat = predict_json('groupby-development','beautyPredictModel',inc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getTopK(array,K):\n",
    "    ind = np.argpartition(array, -K)[-K:][::-1]\n",
    "    prob = array[ind]\n",
    "    return ind, prob\n",
    "\n",
    "def topK_DF(y_hat,K):\n",
    "    col = []\n",
    "    for i in range(1,K+1):\n",
    "        col.append('Prediction'+str(i))\n",
    "        col.append('Probs'+str(i))\n",
    "\n",
    "    df_list = []\n",
    "    for i in y_hat:\n",
    "        labels,prob = getTopK(np.array(i['dense']),K)\n",
    "        classes = encoder.inverse_transform(labels)\n",
    "\n",
    "        result_list = []\n",
    "        for c,p in zip(classes,prob):\n",
    "            result_list.append(c)\n",
    "            result_list.append(p)\n",
    "        df_list.append(result_list)\n",
    "    \n",
    "    return pd.DataFrame(df_list,columns=col)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Prediction1</th>\n",
       "      <th>Probs1</th>\n",
       "      <th>Prediction2</th>\n",
       "      <th>Probs2</th>\n",
       "      <th>Prediction3</th>\n",
       "      <th>Probs3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>lotions &amp; moisturizers</td>\n",
       "      <td>0.330705</td>\n",
       "      <td>hand sanitizers</td>\n",
       "      <td>0.196707</td>\n",
       "      <td>pill cases, organizers &amp; accessories</td>\n",
       "      <td>0.121946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>lotions &amp; moisturizers</td>\n",
       "      <td>0.986280</td>\n",
       "      <td>serums &amp; treatments</td>\n",
       "      <td>0.002268</td>\n",
       "      <td>hand sanitizers</td>\n",
       "      <td>0.002004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>lotions &amp; moisturizers</td>\n",
       "      <td>0.986280</td>\n",
       "      <td>serums &amp; treatments</td>\n",
       "      <td>0.002268</td>\n",
       "      <td>hand sanitizers</td>\n",
       "      <td>0.002004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>lotions &amp; moisturizers</td>\n",
       "      <td>0.920290</td>\n",
       "      <td>hand sanitizers</td>\n",
       "      <td>0.017991</td>\n",
       "      <td>hand soaps</td>\n",
       "      <td>0.017394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>lotions &amp; moisturizers</td>\n",
       "      <td>0.987075</td>\n",
       "      <td>hand sanitizers</td>\n",
       "      <td>0.003121</td>\n",
       "      <td>serums &amp; treatments</td>\n",
       "      <td>0.002967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>lotions &amp; moisturizers</td>\n",
       "      <td>0.987075</td>\n",
       "      <td>hand sanitizers</td>\n",
       "      <td>0.003121</td>\n",
       "      <td>serums &amp; treatments</td>\n",
       "      <td>0.002967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>lotions &amp; moisturizers</td>\n",
       "      <td>0.751206</td>\n",
       "      <td>serums &amp; treatments</td>\n",
       "      <td>0.209895</td>\n",
       "      <td>skin care variety packs</td>\n",
       "      <td>0.008195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>lotions &amp; moisturizers</td>\n",
       "      <td>0.154417</td>\n",
       "      <td>serums &amp; treatments</td>\n",
       "      <td>0.788894</td>\n",
       "      <td>facial cleansers &amp; cosmetic removers</td>\n",
       "      <td>0.034634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>lotions &amp; moisturizers</td>\n",
       "      <td>0.803832</td>\n",
       "      <td>skin treatments</td>\n",
       "      <td>0.077266</td>\n",
       "      <td>sun care &amp; tanning</td>\n",
       "      <td>0.038654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>lotions &amp; moisturizers</td>\n",
       "      <td>0.985399</td>\n",
       "      <td>face &amp; body oils</td>\n",
       "      <td>0.004613</td>\n",
       "      <td>skin treatments</td>\n",
       "      <td>0.002767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>serums &amp; treatments</td>\n",
       "      <td>0.020605</td>\n",
       "      <td>lotions &amp; moisturizers</td>\n",
       "      <td>0.960699</td>\n",
       "      <td>skin treatments</td>\n",
       "      <td>0.002834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>serums &amp; treatments</td>\n",
       "      <td>0.001659</td>\n",
       "      <td>lotions &amp; moisturizers</td>\n",
       "      <td>0.989975</td>\n",
       "      <td>skin treatments</td>\n",
       "      <td>0.000999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>lotions &amp; moisturizers</td>\n",
       "      <td>0.988250</td>\n",
       "      <td>serums &amp; treatments</td>\n",
       "      <td>0.007980</td>\n",
       "      <td>skin treatments</td>\n",
       "      <td>0.001280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>lotions &amp; moisturizers</td>\n",
       "      <td>0.946967</td>\n",
       "      <td>serums &amp; treatments</td>\n",
       "      <td>0.031673</td>\n",
       "      <td>skin treatments</td>\n",
       "      <td>0.012767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>lotions &amp; moisturizers</td>\n",
       "      <td>0.826815</td>\n",
       "      <td>serums &amp; treatments</td>\n",
       "      <td>0.115522</td>\n",
       "      <td>skin treatments</td>\n",
       "      <td>0.024589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>serums &amp; treatments</td>\n",
       "      <td>0.403618</td>\n",
       "      <td>lotions &amp; moisturizers</td>\n",
       "      <td>0.584232</td>\n",
       "      <td>sun care &amp; tanning</td>\n",
       "      <td>0.009484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>serums &amp; treatments</td>\n",
       "      <td>0.753731</td>\n",
       "      <td>foundations &amp; tinted moisturizers</td>\n",
       "      <td>0.101267</td>\n",
       "      <td>sun care &amp; tanning</td>\n",
       "      <td>0.082710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>setting sprays &amp; powders</td>\n",
       "      <td>0.350415</td>\n",
       "      <td>foundations &amp; tinted moisturizers</td>\n",
       "      <td>0.134152</td>\n",
       "      <td>lotions &amp; moisturizers</td>\n",
       "      <td>0.085761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>primers</td>\n",
       "      <td>0.208919</td>\n",
       "      <td>lotions &amp; moisturizers</td>\n",
       "      <td>0.299698</td>\n",
       "      <td>serums &amp; treatments</td>\n",
       "      <td>0.109876</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>serums &amp; treatments</td>\n",
       "      <td>0.358797</td>\n",
       "      <td>lotions &amp; moisturizers</td>\n",
       "      <td>0.629011</td>\n",
       "      <td>exfoliants &amp; masks</td>\n",
       "      <td>0.006638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>lotions &amp; moisturizers</td>\n",
       "      <td>0.900762</td>\n",
       "      <td>skin treatments</td>\n",
       "      <td>0.028931</td>\n",
       "      <td>vitamins, minerals, &amp; dietary supplements</td>\n",
       "      <td>0.012425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>lotions &amp; moisturizers</td>\n",
       "      <td>0.715641</td>\n",
       "      <td>serums &amp; treatments</td>\n",
       "      <td>0.282544</td>\n",
       "      <td>skin treatments</td>\n",
       "      <td>0.000603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>lotions &amp; moisturizers</td>\n",
       "      <td>0.505862</td>\n",
       "      <td>serums &amp; treatments</td>\n",
       "      <td>0.258676</td>\n",
       "      <td>skin treatments</td>\n",
       "      <td>0.077723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>lotions &amp; moisturizers</td>\n",
       "      <td>0.679355</td>\n",
       "      <td>primers</td>\n",
       "      <td>0.142049</td>\n",
       "      <td>toners &amp; astringents</td>\n",
       "      <td>0.045136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>lotions &amp; moisturizers</td>\n",
       "      <td>0.500174</td>\n",
       "      <td>serums &amp; treatments</td>\n",
       "      <td>0.480570</td>\n",
       "      <td>skin treatments</td>\n",
       "      <td>0.009004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>lotions &amp; moisturizers</td>\n",
       "      <td>0.631755</td>\n",
       "      <td>serums &amp; treatments</td>\n",
       "      <td>0.352180</td>\n",
       "      <td>skin treatments</td>\n",
       "      <td>0.004659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>lotions &amp; moisturizers</td>\n",
       "      <td>0.568926</td>\n",
       "      <td>serums &amp; treatments</td>\n",
       "      <td>0.413733</td>\n",
       "      <td>exfoliants &amp; masks</td>\n",
       "      <td>0.006296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>serums &amp; treatments</td>\n",
       "      <td>0.546210</td>\n",
       "      <td>lotions &amp; moisturizers</td>\n",
       "      <td>0.435787</td>\n",
       "      <td>skin treatments</td>\n",
       "      <td>0.006305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>lotions &amp; moisturizers</td>\n",
       "      <td>0.239637</td>\n",
       "      <td>skin care variety packs</td>\n",
       "      <td>0.204791</td>\n",
       "      <td>health, beauty, personal care &amp; hygiene variet...</td>\n",
       "      <td>0.150157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>lotions &amp; moisturizers</td>\n",
       "      <td>0.955528</td>\n",
       "      <td>serums &amp; treatments</td>\n",
       "      <td>0.041694</td>\n",
       "      <td>sun care &amp; tanning</td>\n",
       "      <td>0.000379</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Prediction1    Probs1                        Prediction2  \\\n",
       "0     lotions & moisturizers  0.330705                    hand sanitizers   \n",
       "1     lotions & moisturizers  0.986280                serums & treatments   \n",
       "2     lotions & moisturizers  0.986280                serums & treatments   \n",
       "3     lotions & moisturizers  0.920290                    hand sanitizers   \n",
       "4     lotions & moisturizers  0.987075                    hand sanitizers   \n",
       "5     lotions & moisturizers  0.987075                    hand sanitizers   \n",
       "6     lotions & moisturizers  0.751206                serums & treatments   \n",
       "7     lotions & moisturizers  0.154417                serums & treatments   \n",
       "8     lotions & moisturizers  0.803832                    skin treatments   \n",
       "9     lotions & moisturizers  0.985399                   face & body oils   \n",
       "10       serums & treatments  0.020605             lotions & moisturizers   \n",
       "11       serums & treatments  0.001659             lotions & moisturizers   \n",
       "12    lotions & moisturizers  0.988250                serums & treatments   \n",
       "13    lotions & moisturizers  0.946967                serums & treatments   \n",
       "14    lotions & moisturizers  0.826815                serums & treatments   \n",
       "15       serums & treatments  0.403618             lotions & moisturizers   \n",
       "16       serums & treatments  0.753731  foundations & tinted moisturizers   \n",
       "17  setting sprays & powders  0.350415  foundations & tinted moisturizers   \n",
       "18                   primers  0.208919             lotions & moisturizers   \n",
       "19       serums & treatments  0.358797             lotions & moisturizers   \n",
       "20    lotions & moisturizers  0.900762                    skin treatments   \n",
       "21    lotions & moisturizers  0.715641                serums & treatments   \n",
       "22    lotions & moisturizers  0.505862                serums & treatments   \n",
       "23    lotions & moisturizers  0.679355                            primers   \n",
       "24    lotions & moisturizers  0.500174                serums & treatments   \n",
       "25    lotions & moisturizers  0.631755                serums & treatments   \n",
       "26    lotions & moisturizers  0.568926                serums & treatments   \n",
       "27       serums & treatments  0.546210             lotions & moisturizers   \n",
       "28    lotions & moisturizers  0.239637            skin care variety packs   \n",
       "29    lotions & moisturizers  0.955528                serums & treatments   \n",
       "\n",
       "      Probs2                                        Prediction3    Probs3  \n",
       "0   0.196707               pill cases, organizers & accessories  0.121946  \n",
       "1   0.002268                                    hand sanitizers  0.002004  \n",
       "2   0.002268                                    hand sanitizers  0.002004  \n",
       "3   0.017991                                         hand soaps  0.017394  \n",
       "4   0.003121                                serums & treatments  0.002967  \n",
       "5   0.003121                                serums & treatments  0.002967  \n",
       "6   0.209895                            skin care variety packs  0.008195  \n",
       "7   0.788894               facial cleansers & cosmetic removers  0.034634  \n",
       "8   0.077266                                 sun care & tanning  0.038654  \n",
       "9   0.004613                                    skin treatments  0.002767  \n",
       "10  0.960699                                    skin treatments  0.002834  \n",
       "11  0.989975                                    skin treatments  0.000999  \n",
       "12  0.007980                                    skin treatments  0.001280  \n",
       "13  0.031673                                    skin treatments  0.012767  \n",
       "14  0.115522                                    skin treatments  0.024589  \n",
       "15  0.584232                                 sun care & tanning  0.009484  \n",
       "16  0.101267                                 sun care & tanning  0.082710  \n",
       "17  0.134152                             lotions & moisturizers  0.085761  \n",
       "18  0.299698                                serums & treatments  0.109876  \n",
       "19  0.629011                                 exfoliants & masks  0.006638  \n",
       "20  0.028931          vitamins, minerals, & dietary supplements  0.012425  \n",
       "21  0.282544                                    skin treatments  0.000603  \n",
       "22  0.258676                                    skin treatments  0.077723  \n",
       "23  0.142049                               toners & astringents  0.045136  \n",
       "24  0.480570                                    skin treatments  0.009004  \n",
       "25  0.352180                                    skin treatments  0.004659  \n",
       "26  0.413733                                 exfoliants & masks  0.006296  \n",
       "27  0.435787                                    skin treatments  0.006305  \n",
       "28  0.204791  health, beauty, personal care & hygiene variet...  0.150157  \n",
       "29  0.041694                                 sun care & tanning  0.000379  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_df = topK_DF(y_hat,3)\n",
    "predict_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
