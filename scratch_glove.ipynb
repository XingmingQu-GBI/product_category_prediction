{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Version:  1.15.0\n",
      "Eager mode:  False\n",
      "GPU is available\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "from tensorflow.keras.preprocessing import sequence\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense,GlobalAveragePooling1D,Embedding\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import StratifiedKFold, StratifiedShuffleSplit\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score,accuracy_score\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "\n",
    "\n",
    "\n",
    "import tensorflow as tf\n",
    "print(\"Version: \", tf.__version__)\n",
    "print(\"Eager mode: \", tf.executing_eagerly())\n",
    "print(\"GPU is\", \"available\" if tf.test.is_gpu_available() else \"NOT AVAILABLE\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "from nltk.stem import PorterStemmer\n",
    "from gensim.parsing.preprocessing import remove_stopwords\n",
    "from gensim.parsing.preprocessing import strip_punctuation\n",
    "from gensim.parsing.preprocessing import strip_multiple_whitespaces\n",
    "from gensim.parsing.preprocessing import strip_non_alphanum\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import nltk\n",
    "import spacy\n",
    "import re\n",
    "from unidecode import unidecode\n",
    "import multiprocessing as mp\n",
    "from math import log\n",
    "# basic\n",
    "import os\n",
    "import warnings\n",
    "import json\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "def strip_custom(token):\n",
    "    token = token.replace('&Reg;', \" \")\n",
    "    token = token.replace(\"&lt;\", \"<\")\n",
    "    token = token.replace(\"&times;\", \"\")\n",
    "    token = token.replace(\"&gt;\", \">\")\n",
    "    token = token.replace(\"&quot;\", \"\")\n",
    "    token = token.replace('&nbsp', \" \")\n",
    "    token = token.replace('&copy;', \" \")\n",
    "    token = token.replace('&reg', \" \")\n",
    "    token = token.replace('%20', \" \")\n",
    "    # this has to be last:\n",
    "    token = token.replace(\"&amp;\", \"&\")\n",
    "    token = token.replace(\"â\\x80¢\", \" \")\n",
    "    token = token.replace(\"Â®\", \" \")\n",
    "    token = token.replace(\"Ã©\", \" \")\n",
    "    token = token.replace(\"®\", \" \")\n",
    "    token = token.replace(\"©\", \" \")\n",
    "    token = token.replace(\"™\", \" \")\n",
    "    token = token.replace(\"•\", \"\")\n",
    "    token = token.replace(\"width:99pt\", \"\")\n",
    "    token = token.replace('class=\"xl66\">', '')\n",
    "    #token = re.sub(r\"\\'\", '', token)\n",
    "    token = token.replace('&#160;', ' ')\n",
    "    token = token.replace(\"�\", \"\")\n",
    "    return token\n",
    "\n",
    "\n",
    "def string_processor(token):\n",
    "#     str = str(token)\n",
    "    str = unidecode(token)\n",
    "    str = strip_custom(str)\n",
    "    str = remove_stopwords(str)\n",
    "    str = strip_punctuation(str)\n",
    "    str = strip_non_alphanum(str)\n",
    "#     tokens = sp(str)\n",
    "#     tokens = [token.lemma_ for token in tokens]\n",
    "#     tokens = [porter_stemmer.stem(token) for token in tokens]\n",
    "#     str = \" \".join(tokens)\n",
    "    str = strip_multiple_whitespaces(str)\n",
    "    str = str.strip(' ')\n",
    "    return str\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before drop:  87877\n",
      "after drop:  87854\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bucket_name</th>\n",
       "      <th>feature</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>vitamins, minerals, &amp; dietary supplements</td>\n",
       "      <td>Neuro 1 Orange Cream 1 37 Pound Powder</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>vitamins, minerals, &amp; dietary supplements</td>\n",
       "      <td>Lean 1 Vanilla Raspberry 1 7 Pound Powder</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>vitamins, minerals, &amp; dietary supplements</td>\n",
       "      <td>Lean 1 Fat Burning Meal Replacement Chocolate ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>vitamins, minerals, &amp; dietary supplements</td>\n",
       "      <td>Vegan 1 VANILLA 1 5 Pound Powder</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>vitamins, minerals, &amp; dietary supplements</td>\n",
       "      <td>Vegan 1 BANANA 1 5 Pound Powder</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 bucket_name  \\\n",
       "0  vitamins, minerals, & dietary supplements   \n",
       "1  vitamins, minerals, & dietary supplements   \n",
       "2  vitamins, minerals, & dietary supplements   \n",
       "3  vitamins, minerals, & dietary supplements   \n",
       "4  vitamins, minerals, & dietary supplements   \n",
       "\n",
       "                                             feature  \n",
       "0             Neuro 1 Orange Cream 1 37 Pound Powder  \n",
       "1          Lean 1 Vanilla Raspberry 1 7 Pound Powder  \n",
       "2  Lean 1 Fat Burning Meal Replacement Chocolate ...  \n",
       "3                   Vegan 1 VANILLA 1 5 Pound Powder  \n",
       "4                    Vegan 1 BANANA 1 5 Pound Powder  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('../beauty.csv')\n",
    "feature_column = \"name\"\n",
    "if feature_column == 'name':\n",
    "    df = df[['bucket_name','product_name']]\n",
    "    \n",
    "if feature_column == 'description':\n",
    "    df = df[['bucket_name','description']]\n",
    "\n",
    "df.columns = ['bucket_name', 'feature'] \n",
    "print(\"before drop: \",len(df))\n",
    "df = df.dropna()\n",
    "print(\"after drop: \",len(df))\n",
    "# to lowercase\n",
    "df.bucket_name = df.bucket_name.apply(lambda x : x.lower())\n",
    "df.feature = df.feature.apply(lambda x : string_processor(x))\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "categories: 66\n"
     ]
    }
   ],
   "source": [
    "print(\"categories:\",len(df.bucket_name.unique()))\n",
    "CLASSES = LabelEncoder()\n",
    "df['label']=CLASSES.fit_transform(df['bucket_name'])\n",
    "\n",
    "NUM_OF_CLASS=len(CLASSES.classes_)\n",
    "label = df.label.tolist()\n",
    "encoder_filename = 'model/beauty_saved_encoder.npy'\n",
    "np.save(encoder_filename, CLASSES.classes_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def processing_sequences(x_test,maxlen=16):\n",
    "    print(len(x_test), 'test sequences')\n",
    "\n",
    "    print('Average test sequence length: {}'.format(\n",
    "        np.mean(list(map(len, x_test)))))\n",
    "    print('Pad sequences (samples x time)')\n",
    "    x_test = sequence.pad_sequences(x_test, maxlen=maxlen)\n",
    "\n",
    "    print('x_test shape:', x_test.shape)\n",
    "    return x_test\n",
    "\n",
    "def get_token_for_sentence(corpus,name):\n",
    "#     corpus = df.description.tolist()\n",
    "\n",
    "\n",
    "    vocabulary_size = 30000\n",
    "    tokenizer = Tokenizer(num_words= vocabulary_size, \n",
    "                          filters='!\"#$%&()*+,-./:;<=>?@[\\\\]^_`{|}~\\t\\n', \n",
    "                          lower=True, \n",
    "                          split=' ')\n",
    "\n",
    "    tokenizer.fit_on_texts(corpus)\n",
    "    sequences = tokenizer.texts_to_sequences(corpus)\n",
    "\n",
    "    top_word = len(tokenizer.index_word) +1\n",
    "    print(\"vocab:\",top_word)\n",
    "\n",
    "    # saving\n",
    "    with open(name+'tokenizer.pickle', 'wb') as handle:\n",
    "        pickle.dump(tokenizer, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "        \n",
    "    return np.array(sequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vocab: 17293\n",
      "vocab: 80389\n",
      "87210 test sequences\n",
      "Average test sequence length: 7.140247678018576\n",
      "Pad sequences (samples x time)\n",
      "x_test shape: (87210, 16)\n",
      "87210 test sequences\n",
      "Average test sequence length: 69.83360853113174\n",
      "Pad sequences (samples x time)\n",
      "x_test shape: (87210, 75)\n"
     ]
    }
   ],
   "source": [
    "name_token = get_token_for_sentence(df.product_name.tolist(),'name')\n",
    "des_token = get_token_for_sentence(df.description.tolist(),'des')\n",
    "\n",
    "X_name = processing_sequences(name_token,maxlen=16)\n",
    "X_des = processing_sequences(des_token,maxlen=75)\n",
    "y = np.array(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_model(x_train, x_test, y_train, y_test,fold_number,feature):\n",
    "    current_model_name = \"model/\"+feature+str(fold_number)+\"_best.h5\"\n",
    "\n",
    "\n",
    "    max_features = 30000\n",
    "    batch_size = 32\n",
    "    embedding_dims = 100\n",
    "    epochs = 35\n",
    "    Patience = 3\n",
    "    maxlen = x_train.shape[1]\n",
    "\n",
    "\n",
    "    print('Build model...')\n",
    "    model = Sequential()\n",
    "\n",
    "    # we start off with an efficient embedding layer which maps\n",
    "    # our vocab indices into embedding_dims dimensions\n",
    "    model.add(Embedding(max_features,\n",
    "                        embedding_dims,\n",
    "                        input_length=maxlen))\n",
    "\n",
    "    # we add a GlobalAveragePooling1D, which will average the embeddings\n",
    "    # of all words in the document\n",
    "    model.add(GlobalAveragePooling1D())\n",
    "\n",
    "    # We project onto a single unit output layer, and squash it with a sigmoid:\n",
    "    model.add(Dense(NUM_OF_CLASS, activation='softmax'))\n",
    "\n",
    "    model.compile(loss='sparse_categorical_crossentropy',\n",
    "                  optimizer='adam',\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    print(model.summary())\n",
    "    checkpoint = ModelCheckpoint(current_model_name, monitor='val_loss', verbose=1, save_best_only=True)\n",
    "    history = model.fit(x_train, y_train,\n",
    "              batch_size=batch_size,\n",
    "              epochs=epochs,\n",
    "              validation_data=(x_test, y_test),\n",
    "              callbacks=[EarlyStopping(monitor='val_loss', patience=Patience),checkpoint], \n",
    "              verbose=1 )\n",
    "    \n",
    "    model.load_weights(current_model_name)\n",
    "#     yhat = np.argmax(model.predict(x_test),axis=1)\n",
    "#     return f1_score(y_test,yhat,average='macro')\n",
    "    yhat = model.predict(x_test)\n",
    "    \n",
    "    print('\\n\\n in validation')\n",
    "\n",
    "    print(classification_report(y_test, np.argmax(yhat ,axis=1), target_names=CLASSES.classes_))\n",
    "    model.save(feature+'my_model.h5')\n",
    "    return yhat\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_name_train, X_name_test, X_des_train, X_des_test,y_train, y_test = train_test_split(X_name, X_des, y, test_size=0.01, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Build model...\n",
      "WARNING:tensorflow:From /home/jupyter/tf115/lib/python3.5/site-packages/tensorflow_core/python/keras/initializers.py:119: calling RandomUniform.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:From /home/jupyter/tf115/lib/python3.5/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, 16, 100)           3000000   \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d (Gl (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 66)                6666      \n",
      "=================================================================\n",
      "Total params: 3,006,666\n",
      "Trainable params: 3,006,666\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 86337 samples, validate on 873 samples\n",
      "Epoch 1/35\n",
      "86048/86337 [============================>.] - ETA: 0s - loss: 1.5901 - acc: 0.6455\n",
      "Epoch 00001: val_loss improved from inf to 0.74584, saving model to model/namelocal_best.h5\n",
      "86337/86337 [==============================] - 9s 106us/sample - loss: 1.5870 - acc: 0.6461 - val_loss: 0.7458 - val_acc: 0.8167\n",
      "Epoch 2/35\n",
      "86272/86337 [============================>.] - ETA: 0s - loss: 0.4652 - acc: 0.8904\n",
      "Epoch 00002: val_loss improved from 0.74584 to 0.40733, saving model to model/namelocal_best.h5\n",
      "86337/86337 [==============================] - 9s 100us/sample - loss: 0.4654 - acc: 0.8903 - val_loss: 0.4073 - val_acc: 0.8958\n",
      "Epoch 3/35\n",
      "86272/86337 [============================>.] - ETA: 0s - loss: 0.2651 - acc: 0.9328\n",
      "Epoch 00003: val_loss improved from 0.40733 to 0.31924, saving model to model/namelocal_best.h5\n",
      "86337/86337 [==============================] - 9s 100us/sample - loss: 0.2650 - acc: 0.9329 - val_loss: 0.3192 - val_acc: 0.9152\n",
      "Epoch 4/35\n",
      "85888/86337 [============================>.] - ETA: 0s - loss: 0.1945 - acc: 0.9480\n",
      "Epoch 00004: val_loss improved from 0.31924 to 0.28635, saving model to model/namelocal_best.h5\n",
      "86337/86337 [==============================] - 9s 100us/sample - loss: 0.1945 - acc: 0.9481 - val_loss: 0.2864 - val_acc: 0.9324\n",
      "Epoch 5/35\n",
      "85856/86337 [============================>.] - ETA: 0s - loss: 0.1559 - acc: 0.9568\n",
      "Epoch 00005: val_loss improved from 0.28635 to 0.27026, saving model to model/namelocal_best.h5\n",
      "86337/86337 [==============================] - 9s 100us/sample - loss: 0.1558 - acc: 0.9569 - val_loss: 0.2703 - val_acc: 0.9370\n",
      "Epoch 6/35\n",
      "85952/86337 [============================>.] - ETA: 0s - loss: 0.1298 - acc: 0.9643\n",
      "Epoch 00006: val_loss improved from 0.27026 to 0.26010, saving model to model/namelocal_best.h5\n",
      "86337/86337 [==============================] - 9s 101us/sample - loss: 0.1300 - acc: 0.9642 - val_loss: 0.2601 - val_acc: 0.9381\n",
      "Epoch 7/35\n",
      "86112/86337 [============================>.] - ETA: 0s - loss: 0.1114 - acc: 0.9684\n",
      "Epoch 00007: val_loss improved from 0.26010 to 0.25770, saving model to model/namelocal_best.h5\n",
      "86337/86337 [==============================] - 9s 102us/sample - loss: 0.1113 - acc: 0.9685 - val_loss: 0.2577 - val_acc: 0.9416\n",
      "Epoch 8/35\n",
      "86304/86337 [============================>.] - ETA: 0s - loss: 0.0969 - acc: 0.9724\n",
      "Epoch 00008: val_loss did not improve from 0.25770\n",
      "86337/86337 [==============================] - 9s 101us/sample - loss: 0.0970 - acc: 0.9724 - val_loss: 0.2578 - val_acc: 0.9381\n",
      "Epoch 9/35\n",
      "86112/86337 [============================>.] - ETA: 0s - loss: 0.0852 - acc: 0.9753\n",
      "Epoch 00009: val_loss did not improve from 0.25770\n",
      "86337/86337 [==============================] - 9s 102us/sample - loss: 0.0852 - acc: 0.9753 - val_loss: 0.2591 - val_acc: 0.9427\n",
      "Epoch 10/35\n",
      "86304/86337 [============================>.] - ETA: 0s - loss: 0.0757 - acc: 0.9784\n",
      "Epoch 00010: val_loss did not improve from 0.25770\n",
      "86337/86337 [==============================] - 9s 102us/sample - loss: 0.0758 - acc: 0.9783 - val_loss: 0.2653 - val_acc: 0.9416\n",
      "\n",
      "\n",
      " in validation\n",
      "                                                       precision    recall  f1-score   support\n",
      "\n",
      "                                     after shave care       1.00      1.00      1.00         2\n",
      "                                barrier contraception       1.00      1.00      1.00         2\n",
      "                              bath & shower additives       1.00      0.75      0.86         4\n",
      "                          bathing tools & accessories       1.00      1.00      1.00         2\n",
      "                                                blush       1.00      1.00      1.00         3\n",
      "                                body washing products       0.89      0.89      0.89        18\n",
      "                      bronzer, contour, & highlighter       0.83      1.00      0.91         5\n",
      "                          combination makeup products       1.00      1.00      1.00         1\n",
      "         combination personal care & hygiene products       1.00      1.00      1.00         2\n",
      "                        concealers & color correctors       0.88      1.00      0.93         7\n",
      "                         deodorants & antiperspirants       1.00      1.00      1.00        10\n",
      "                                  diagnostic monitors       1.00      1.00      1.00         2\n",
      "                                     diagnostic tests       1.00      1.00      1.00         1\n",
      "                                   exfoliants & masks       0.90      1.00      0.95        18\n",
      "                                     eyebrow products       0.86      1.00      0.92         6\n",
      "                                            eyeliners       1.00      1.00      1.00         8\n",
      "                                            eyeshadow       0.90      1.00      0.95         9\n",
      "                                     face & body oils       0.82      1.00      0.90         9\n",
      "                 facial cleansers & cosmetic removers       0.92      0.86      0.89        14\n",
      "                          false eyelashes & adhesives       1.00      1.00      1.00         3\n",
      "                                     feminine hygiene       1.00      1.00      1.00         6\n",
      "                    foundations & tinted moisturizers       1.00      0.86      0.92        21\n",
      "                                           fragrances       0.96      1.00      0.98        46\n",
      "       gastrointestinal/indigestion/nausea treatments       1.00      0.80      0.89         5\n",
      "                           hair cleaning & treatments       0.98      0.95      0.96        43\n",
      "                                           hair color       1.00      1.00      1.00        13\n",
      "                        hair removal tools & products       1.00      0.83      0.91         6\n",
      "                                hair styling products       0.83      0.83      0.83        12\n",
      "                                   hair styling tools       0.75      1.00      0.86         3\n",
      "                                      hand sanitizers       0.50      1.00      0.67         1\n",
      "                                           hand soaps       1.00      1.00      1.00         4\n",
      "health, beauty, personal care & hygiene variety packs       0.60      0.60      0.60         5\n",
      "                  homeopathic/naturopathic treatments       0.96      0.88      0.92        25\n",
      "                                 hot & cold therapies       1.00      0.50      0.67         2\n",
      "              intimate lubricants & topical enhancers       1.00      1.00      1.00         2\n",
      "                                             lip care       1.00      1.00      1.00         8\n",
      "                                           lip liners       1.00      1.00      1.00         4\n",
      "                         lipsticks, glosses, & stains       1.00      0.94      0.97        34\n",
      "                               lotions & moisturizers       0.84      0.84      0.84        32\n",
      "                        makeup products variety packs       1.00      1.00      1.00         1\n",
      "                           makeup tools & accessories       1.00      0.71      0.83         7\n",
      "                                              mascara       1.00      0.86      0.92         7\n",
      "                       mouth washes, rinses, & sprays       1.00      1.00      1.00         3\n",
      "                            nail & cuticle treatments       1.00      1.00      1.00         1\n",
      "                            nail polishes & adornment       0.95      1.00      0.97        19\n",
      "                             nail tools & accessories       1.00      1.00      1.00         2\n",
      "              nasal/sinus/respiratory care/treatments       1.00      0.85      0.92        13\n",
      "                               oral cleaning products       1.00      1.00      1.00        12\n",
      "                      pain relievers & fever reducers       1.00      1.00      1.00         5\n",
      "                personal care & hygiene variety packs       1.00      1.00      1.00         1\n",
      "                               personal hygiene wipes       0.00      0.00      0.00         1\n",
      "                 pill cases, organizers & accessories       1.00      1.00      1.00         1\n",
      "                                              primers       1.00      0.50      0.67         4\n",
      "                                  serums & treatments       0.72      0.95      0.82        22\n",
      "                             setting sprays & powders       1.00      1.00      1.00         3\n",
      "                       sexual toys/aids & accessories       1.00      0.67      0.80         3\n",
      "                                   shaving lubricants       1.00      1.00      1.00         3\n",
      "                        skin care tools & accessories       1.00      1.00      1.00         3\n",
      "                              skin care variety packs       0.50      0.50      0.50         2\n",
      "                                      skin treatments       1.00      0.56      0.71         9\n",
      "                       sleep & mood/emotional support       0.71      0.77      0.74        13\n",
      "                                   sun care & tanning       1.00      0.88      0.93         8\n",
      "                                           sunglasses       1.00      1.00      1.00         1\n",
      "                          toilet paper & toilet wipes       1.00      1.00      1.00         1\n",
      "                                 toners & astringents       1.00      1.00      1.00         4\n",
      "            vitamins, minerals, & dietary supplements       0.97      0.98      0.98       326\n",
      "\n",
      "                                             accuracy                           0.94       873\n",
      "                                            macro avg       0.93      0.91      0.91       873\n",
      "                                         weighted avg       0.95      0.94      0.94       873\n",
      "\n",
      "Build model...\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 75, 100)           3000000   \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d_1 ( (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 66)                6666      \n",
      "=================================================================\n",
      "Total params: 3,006,666\n",
      "Trainable params: 3,006,666\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 86337 samples, validate on 873 samples\n",
      "Epoch 1/35\n",
      "86272/86337 [============================>.] - ETA: 0s - loss: 1.7105 - acc: 0.6080\n",
      "Epoch 00001: val_loss improved from inf to 0.94174, saving model to model/descriptionlocal_best.h5\n",
      "86337/86337 [==============================] - 9s 104us/sample - loss: 1.7099 - acc: 0.6081 - val_loss: 0.9417 - val_acc: 0.7835\n",
      "Epoch 2/35\n",
      "86016/86337 [============================>.] - ETA: 0s - loss: 0.6952 - acc: 0.8361\n",
      "Epoch 00002: val_loss improved from 0.94174 to 0.59787, saving model to model/descriptionlocal_best.h5\n",
      "86337/86337 [==============================] - 9s 101us/sample - loss: 0.6946 - acc: 0.8362 - val_loss: 0.5979 - val_acc: 0.8568\n",
      "Epoch 3/35\n",
      "86240/86337 [============================>.] - ETA: 0s - loss: 0.4631 - acc: 0.8895\n",
      "Epoch 00003: val_loss improved from 0.59787 to 0.48192, saving model to model/descriptionlocal_best.h5\n",
      "86337/86337 [==============================] - 9s 101us/sample - loss: 0.4630 - acc: 0.8895 - val_loss: 0.4819 - val_acc: 0.8820\n",
      "Epoch 4/35\n",
      "85952/86337 [============================>.] - ETA: 0s - loss: 0.3595 - acc: 0.9117\n",
      "Epoch 00004: val_loss improved from 0.48192 to 0.42680, saving model to model/descriptionlocal_best.h5\n",
      "86337/86337 [==============================] - 9s 101us/sample - loss: 0.3595 - acc: 0.9117 - val_loss: 0.4268 - val_acc: 0.8900\n",
      "Epoch 5/35\n",
      "85984/86337 [============================>.] - ETA: 0s - loss: 0.2970 - acc: 0.9259\n",
      "Epoch 00005: val_loss improved from 0.42680 to 0.40367, saving model to model/descriptionlocal_best.h5\n",
      "86337/86337 [==============================] - 9s 103us/sample - loss: 0.2968 - acc: 0.9259 - val_loss: 0.4037 - val_acc: 0.9003\n",
      "Epoch 6/35\n",
      "86304/86337 [============================>.] - ETA: 0s - loss: 0.2525 - acc: 0.9362\n",
      "Epoch 00006: val_loss improved from 0.40367 to 0.38214, saving model to model/descriptionlocal_best.h5\n",
      "86337/86337 [==============================] - 9s 101us/sample - loss: 0.2526 - acc: 0.9362 - val_loss: 0.3821 - val_acc: 0.9061\n",
      "Epoch 7/35\n",
      "86272/86337 [============================>.] - ETA: 0s - loss: 0.2186 - acc: 0.9450\n",
      "Epoch 00007: val_loss improved from 0.38214 to 0.37871, saving model to model/descriptionlocal_best.h5\n",
      "86337/86337 [==============================] - 9s 102us/sample - loss: 0.2187 - acc: 0.9450 - val_loss: 0.3787 - val_acc: 0.9095\n",
      "Epoch 8/35\n",
      "86304/86337 [============================>.] - ETA: 0s - loss: 0.1919 - acc: 0.9519\n",
      "Epoch 00008: val_loss improved from 0.37871 to 0.37663, saving model to model/descriptionlocal_best.h5\n",
      "86337/86337 [==============================] - 9s 100us/sample - loss: 0.1919 - acc: 0.9519 - val_loss: 0.3766 - val_acc: 0.9118\n",
      "Epoch 9/35\n",
      "85952/86337 [============================>.] - ETA: 0s - loss: 0.1699 - acc: 0.9566\n",
      "Epoch 00009: val_loss did not improve from 0.37663\n",
      "86337/86337 [==============================] - 9s 100us/sample - loss: 0.1698 - acc: 0.9566 - val_loss: 0.3788 - val_acc: 0.9129\n",
      "Epoch 10/35\n",
      "86336/86337 [============================>.] - ETA: 0s - loss: 0.1512 - acc: 0.9616\n",
      "Epoch 00010: val_loss did not improve from 0.37663\n",
      "86337/86337 [==============================] - 9s 101us/sample - loss: 0.1512 - acc: 0.9616 - val_loss: 0.3795 - val_acc: 0.9152\n",
      "Epoch 11/35\n",
      "86080/86337 [============================>.] - ETA: 0s - loss: 0.1353 - acc: 0.9657\n",
      "Epoch 00011: val_loss did not improve from 0.37663\n",
      "86337/86337 [==============================] - 9s 101us/sample - loss: 0.1353 - acc: 0.9657 - val_loss: 0.3819 - val_acc: 0.9141\n",
      "\n",
      "\n",
      " in validation\n",
      "                                                       precision    recall  f1-score   support\n",
      "\n",
      "                                     after shave care       1.00      1.00      1.00         2\n",
      "                                barrier contraception       1.00      1.00      1.00         2\n",
      "                              bath & shower additives       0.80      1.00      0.89         4\n",
      "                          bathing tools & accessories       1.00      1.00      1.00         2\n",
      "                                                blush       1.00      1.00      1.00         3\n",
      "                                body washing products       0.94      0.83      0.88        18\n",
      "                      bronzer, contour, & highlighter       1.00      0.80      0.89         5\n",
      "                          combination makeup products       1.00      1.00      1.00         1\n",
      "         combination personal care & hygiene products       1.00      1.00      1.00         2\n",
      "                        concealers & color correctors       0.88      1.00      0.93         7\n",
      "                         deodorants & antiperspirants       0.83      1.00      0.91        10\n",
      "                                  diagnostic monitors       1.00      1.00      1.00         2\n",
      "                                     diagnostic tests       1.00      1.00      1.00         1\n",
      "                                   exfoliants & masks       0.82      0.78      0.80        18\n",
      "                                     eyebrow products       0.86      1.00      0.92         6\n",
      "                                            eyeliners       0.89      1.00      0.94         8\n",
      "                                            eyeshadow       1.00      0.78      0.88         9\n",
      "                                     face & body oils       0.88      0.78      0.82         9\n",
      "                 facial cleansers & cosmetic removers       0.87      0.93      0.90        14\n",
      "                          false eyelashes & adhesives       1.00      1.00      1.00         3\n",
      "                                     feminine hygiene       1.00      1.00      1.00         6\n",
      "                    foundations & tinted moisturizers       0.88      1.00      0.93        21\n",
      "                                           fragrances       0.90      0.93      0.91        46\n",
      "       gastrointestinal/indigestion/nausea treatments       1.00      0.80      0.89         5\n",
      "                           hair cleaning & treatments       0.95      0.91      0.93        43\n",
      "                                           hair color       1.00      1.00      1.00        13\n",
      "                        hair removal tools & products       1.00      0.83      0.91         6\n",
      "                                hair styling products       0.92      0.92      0.92        12\n",
      "                                   hair styling tools       0.75      1.00      0.86         3\n",
      "                                      hand sanitizers       1.00      1.00      1.00         1\n",
      "                                           hand soaps       1.00      1.00      1.00         4\n",
      "health, beauty, personal care & hygiene variety packs       0.33      0.40      0.36         5\n",
      "                  homeopathic/naturopathic treatments       0.91      0.80      0.85        25\n",
      "                                 hot & cold therapies       1.00      1.00      1.00         2\n",
      "              intimate lubricants & topical enhancers       1.00      0.50      0.67         2\n",
      "                                             lip care       1.00      0.88      0.93         8\n",
      "                                           lip liners       1.00      0.75      0.86         4\n",
      "                         lipsticks, glosses, & stains       0.94      1.00      0.97        34\n",
      "                               lotions & moisturizers       0.84      0.84      0.84        32\n",
      "                        makeup products variety packs       0.00      0.00      0.00         1\n",
      "                           makeup tools & accessories       1.00      0.57      0.73         7\n",
      "                                              mascara       0.86      0.86      0.86         7\n",
      "                       mouth washes, rinses, & sprays       1.00      0.67      0.80         3\n",
      "                            nail & cuticle treatments       0.00      0.00      0.00         1\n",
      "                            nail polishes & adornment       1.00      1.00      1.00        19\n",
      "                             nail tools & accessories       1.00      1.00      1.00         2\n",
      "              nasal/sinus/respiratory care/treatments       0.91      0.77      0.83        13\n",
      "                               oral cleaning products       0.92      0.92      0.92        12\n",
      "                      pain relievers & fever reducers       1.00      0.80      0.89         5\n",
      "                personal care & hygiene variety packs       0.50      1.00      0.67         1\n",
      "                               personal hygiene wipes       1.00      1.00      1.00         1\n",
      "                 pill cases, organizers & accessories       1.00      1.00      1.00         1\n",
      "                                              primers       0.75      0.75      0.75         4\n",
      "                                  serums & treatments       0.79      0.86      0.83        22\n",
      "                             setting sprays & powders       0.50      0.33      0.40         3\n",
      "                       sexual toys/aids & accessories       1.00      1.00      1.00         3\n",
      "                                   shaving lubricants       1.00      1.00      1.00         3\n",
      "                        skin care tools & accessories       1.00      0.67      0.80         3\n",
      "                              skin care variety packs       1.00      0.50      0.67         2\n",
      "                                      skin treatments       0.75      0.67      0.71         9\n",
      "                       sleep & mood/emotional support       0.54      0.54      0.54        13\n",
      "                                   sun care & tanning       0.83      0.62      0.71         8\n",
      "                                           sunglasses       1.00      1.00      1.00         1\n",
      "                          toilet paper & toilet wipes       1.00      1.00      1.00         1\n",
      "                                 toners & astringents       0.75      0.75      0.75         4\n",
      "            vitamins, minerals, & dietary supplements       0.95      0.98      0.97       326\n",
      "\n",
      "                                             accuracy                           0.91       873\n",
      "                                            macro avg       0.88      0.84      0.85       873\n",
      "                                         weighted avg       0.91      0.91      0.91       873\n",
      "\n",
      "                                                       precision    recall  f1-score   support\n",
      "\n",
      "                                     after shave care     1.0000    1.0000    1.0000         2\n",
      "                                barrier contraception     1.0000    1.0000    1.0000         2\n",
      "                              bath & shower additives     0.8000    1.0000    0.8889         4\n",
      "                          bathing tools & accessories     1.0000    1.0000    1.0000         2\n",
      "                                                blush     1.0000    1.0000    1.0000         3\n",
      "                                body washing products     0.9444    0.9444    0.9444        18\n",
      "                      bronzer, contour, & highlighter     1.0000    0.8000    0.8889         5\n",
      "                          combination makeup products     1.0000    1.0000    1.0000         1\n",
      "         combination personal care & hygiene products     1.0000    1.0000    1.0000         2\n",
      "                        concealers & color correctors     0.8750    1.0000    0.9333         7\n",
      "                         deodorants & antiperspirants     1.0000    1.0000    1.0000        10\n",
      "                                  diagnostic monitors     1.0000    1.0000    1.0000         2\n",
      "                                     diagnostic tests     1.0000    1.0000    1.0000         1\n",
      "                                   exfoliants & masks     0.8947    0.9444    0.9189        18\n",
      "                                     eyebrow products     0.8571    1.0000    0.9231         6\n",
      "                                            eyeliners     0.8889    1.0000    0.9412         8\n",
      "                                            eyeshadow     1.0000    0.8889    0.9412         9\n",
      "                                     face & body oils     1.0000    0.8889    0.9412         9\n",
      "                 facial cleansers & cosmetic removers     1.0000    1.0000    1.0000        14\n",
      "                          false eyelashes & adhesives     1.0000    1.0000    1.0000         3\n",
      "                                     feminine hygiene     1.0000    1.0000    1.0000         6\n",
      "                    foundations & tinted moisturizers     0.9545    1.0000    0.9767        21\n",
      "                                           fragrances     0.9388    1.0000    0.9684        46\n",
      "       gastrointestinal/indigestion/nausea treatments     1.0000    0.8000    0.8889         5\n",
      "                           hair cleaning & treatments     0.9535    0.9535    0.9535        43\n",
      "                                           hair color     1.0000    1.0000    1.0000        13\n",
      "                        hair removal tools & products     1.0000    0.8333    0.9091         6\n",
      "                                hair styling products     0.8462    0.9167    0.8800        12\n",
      "                                   hair styling tools     0.7500    1.0000    0.8571         3\n",
      "                                      hand sanitizers     1.0000    1.0000    1.0000         1\n",
      "                                           hand soaps     1.0000    1.0000    1.0000         4\n",
      "health, beauty, personal care & hygiene variety packs     0.7500    0.6000    0.6667         5\n",
      "                  homeopathic/naturopathic treatments     0.9565    0.8800    0.9167        25\n",
      "                                 hot & cold therapies     1.0000    0.5000    0.6667         2\n",
      "              intimate lubricants & topical enhancers     1.0000    1.0000    1.0000         2\n",
      "                                             lip care     1.0000    1.0000    1.0000         8\n",
      "                                           lip liners     1.0000    1.0000    1.0000         4\n",
      "                         lipsticks, glosses, & stains     0.9714    1.0000    0.9855        34\n",
      "                               lotions & moisturizers     0.8667    0.8125    0.8387        32\n",
      "                        makeup products variety packs     0.0000    0.0000    0.0000         1\n",
      "                           makeup tools & accessories     1.0000    0.8571    0.9231         7\n",
      "                                              mascara     1.0000    0.8571    0.9231         7\n",
      "                       mouth washes, rinses, & sprays     1.0000    0.6667    0.8000         3\n",
      "                            nail & cuticle treatments     1.0000    1.0000    1.0000         1\n",
      "                            nail polishes & adornment     1.0000    1.0000    1.0000        19\n",
      "                             nail tools & accessories     1.0000    1.0000    1.0000         2\n",
      "              nasal/sinus/respiratory care/treatments     0.9167    0.8462    0.8800        13\n",
      "                               oral cleaning products     0.9231    1.0000    0.9600        12\n",
      "                      pain relievers & fever reducers     1.0000    1.0000    1.0000         5\n",
      "                personal care & hygiene variety packs     1.0000    1.0000    1.0000         1\n",
      "                               personal hygiene wipes     1.0000    1.0000    1.0000         1\n",
      "                 pill cases, organizers & accessories     1.0000    1.0000    1.0000         1\n",
      "                                              primers     1.0000    0.5000    0.6667         4\n",
      "                                  serums & treatments     0.7692    0.9091    0.8333        22\n",
      "                             setting sprays & powders     1.0000    1.0000    1.0000         3\n",
      "                       sexual toys/aids & accessories     1.0000    1.0000    1.0000         3\n",
      "                                   shaving lubricants     1.0000    1.0000    1.0000         3\n",
      "                        skin care tools & accessories     1.0000    1.0000    1.0000         3\n",
      "                              skin care variety packs     1.0000    0.5000    0.6667         2\n",
      "                                      skin treatments     1.0000    0.6667    0.8000         9\n",
      "                       sleep & mood/emotional support     0.5714    0.6154    0.5926        13\n",
      "                                   sun care & tanning     1.0000    0.8750    0.9333         8\n",
      "                                           sunglasses     1.0000    1.0000    1.0000         1\n",
      "                          toilet paper & toilet wipes     1.0000    1.0000    1.0000         1\n",
      "                                 toners & astringents     1.0000    1.0000    1.0000         4\n",
      "            vitamins, minerals, & dietary supplements     0.9698    0.9847    0.9772       326\n",
      "\n",
      "                                             accuracy                         0.9462       873\n",
      "                                            macro avg     0.9454    0.9097    0.9210       873\n",
      "                                         weighted avg     0.9476    0.9462    0.9446       873\n",
      "\n"
     ]
    }
   ],
   "source": [
    "name_yhat = eval_model(X_name_train, X_name_test, y_train, y_test,fold_number='local',feature='name')\n",
    "des_yhat = eval_model(X_des_train, X_des_test, y_train, y_test,fold_number='local',feature='description')\n",
    "\n",
    "yhat = np.argmax(name_yhat+des_yhat,axis=1)\n",
    "\n",
    "\n",
    "score = f1_score(y_test,yhat,average='macro')\n",
    "print(classification_report(y_test, yhat, target_names=CLASSES.classes_,digits=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf115",
   "language": "python",
   "name": "tf115"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
